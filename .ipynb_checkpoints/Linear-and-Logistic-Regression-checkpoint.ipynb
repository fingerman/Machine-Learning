{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nose.tools import *\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear and Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read the data \n",
    "In this survey it will be worked with the Bank Marketing Data Set, which can be obtained from following [link](https://archive.ics.uci.edu/ml/machine-learning-databases/00222/).  The data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be ('yes') or not ('no') subscribed. More detailed description is provided [here](https://archive.ics.uci.edu/ml/datasets/bank+marketing).\n",
    "\n",
    "The data you need to read is the `bank.csv` file in the `data` folder (use \";\" as the column separator). The `bank-names.txt` file contains information about the dataset. Read it and you'll get some information about what it contains.\n",
    "\n",
    "Read the dataset using `pandas` (you can use the library with the alias `pd`). Save it in the `bank_data` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6f01f6b16d4cc0c6d70623ffabbb26a3",
     "grade": false,
     "grade_id": "cell-1d1926bb7ca098b5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bank_data = pd.read_csv('bank/bank.csv', sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_equal(bank_data.shape, (4521, 17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "04646f4e1d61554f24896f2580a9c6f6",
     "grade": true,
     "grade_id": "cell-f5eca6423dc08236",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_not_none(bank_data)\n",
    "assert_equal(bank_data.shape, (4521, 17))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Separate features and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the explanatory variables and the output variable (it's called `y` in this case). Create two new variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4ca3bea52dd3a9545de67ec525ab76ab",
     "grade": false,
     "grade_id": "cell-37165798a822868a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "bank_features = bank_data.drop(\"y\", axis = 1) # explanatory features - 16 total\n",
    "bank_output = bank_data[[\"y\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "55f252f336e71ee415afaf1e5c70dada",
     "grade": true,
     "grade_id": "cell-bcdd5d7fa2460962",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(bank_features.shape, (4521, 16))\n",
    "assert_equal(bank_output.shape, (4521, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3.  Convert categorical variables\n",
    "Convert all categorical variables in `bank_features` into indicator variables (dummies). Save the result in the same variable. (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "eea54c44bc2385c397b31f95b4236228",
     "grade": false,
     "grade_id": "cell-e08709f9c53b50e0",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "cols_to_transform = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
    "bank_features = pd.get_dummies(data=bank_features, columns = cols_to_transform )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "78d4866a669be1693501dec677182162",
     "grade": true,
     "grade_id": "cell-526e429563d680df",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(bank_features.shape, (4521, 51))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(assert_equal(bank_features.shape, (4521, 51)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the `bank_output` variable to an indicator variable. This can be done in many ways. \n",
    "The goal is to **rewrite the column** (replace the values): it should be numeric, and be equal to 1 if the original value was \"yes\" and 0 otherwise. (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d22b12e35316410cff3d988a7ba30358",
     "grade": false,
     "grade_id": "cell-78040e5a440b5171",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4619: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "bank_output['y'].replace('yes', 1 ,inplace=True)\n",
    "bank_output['y'].replace('no', 0 ,inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ad86b5c5be9567ceca42d0d6c1ccf558",
     "grade": true,
     "grade_id": "cell-280b855388c11990",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(bank_output['y'].dtype, np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Perform logistic regression on the original features \n",
    "Perform logistic regression. Save the model in the variable `bank_model`. \n",
    "\n",
    "Use all the data. This is not generally recommended but we'll think of a workaround next time.\n",
    "\n",
    "Pass a large number for the parameter `C = 1e6` (which is equivalent to `C = 1000000`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4c2a3af88dc6e6dec25f82993e9d04c0",
     "grade": false,
     "grade_id": "cell-46045c65058e5e8b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "bank_model = LogisticRegression(C=1e6).fit(bank_features, bank_output['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b342c65cc5749cea353896d940905921",
     "grade": true,
     "grade_id": "cell-17cefb4e8081fcdb",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_not_none(bank_model)\n",
    "assert_equal(bank_model.C, 1e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5. Get an estimate of the model performance (1 point)\n",
    "Use `bank_model.score()` to get an accuracy score. We'll talk about what it represents later in the course. Save the resulting score in the variable `accuracy_score`. To generate the score, use all data. Once again, this is not what we do usually but it's a good start anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d1c437ca23c62db5c52ef7dd52827f0d",
     "grade": false,
     "grade_id": "cell-c1ccd2f4394c67ee",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9042247290422473\n"
     ]
    }
   ],
   "source": [
    "accuracy_score = bank_model.score(bank_features, bank_output['y'])\n",
    "print(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f36e16bbd9113c991a34051fb6d4e3f2",
     "grade": true,
     "grade_id": "cell-52c9269442900910",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_almost_equal(accuracy_score, 0.9042247290422473, delta = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to make a note here. If we explore how the output classes are distributed, we can see that \"class 1\" is about 11.5% of all samples, i.e. very few clients actually subscribed after the call, which is expected. This means the data is **highly imbalanced**. In this case, accuracy is not a good measure of the overall model performance. We have to look at other scoring measures to get a better estimate of what's going on.\n",
    "\n",
    "But once again, we're just getting started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAD19JREFUeJzt3X+snmV9x/H3hxbQRQcoR0da4sFYF9FEZBWZbovCBlWXlS3i6hbpTGf/GFv8sThhy2KmkmCyDaKbmk46KjHUDt1AJWOdgG6JAq0yFBih4g86CK1rRZ1BLX73x7mqj/X8eK62z3nO4bxfyclz39/7up/zfZKTfM7947nuVBWSJA3rmHE3IElaXAwOSVIXg0OS1MXgkCR1MTgkSV0MDklSF4NDktTF4JAkdTE4JEldlo+7gVE4+eSTa3JyctxtSNKisnPnzm9W1cRc456QwTE5OcmOHTvG3YYkLSpJvj7MOE9VSZK6GBySpC4GhySpi8EhSepicEiSuhgckqQuBockqYvBIUnqYnBIkro8Ib85fqQmL/nUuFvQAvW1y1897hYA/0Y1s/n4G/WIQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUheDQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV1GHhxJliX5YpJPtvXTktyW5P4kH01yXKsf39Z3te2TA+9xaavfl+T8UfcsSZrZfBxxvAm4d2D9PcAVVbUK2A9saPUNwP6qeg5wRRtHktOBdcDzgTXA+5Msm4e+JUnTGGlwJFkJvBr4UFsPcA5wXRuyBbigLa9t67Tt57bxa4GtVfX9qvoqsAs4a5R9S5JmNuojjiuBPwN+1NafDnyrqg609d3Aira8AngQoG1/tI3/cX2afSRJ82xkwZHkN4E9VbVzsDzN0Jpj22z7DP6+jUl2JNmxd+/e7n4lScMZ5RHHy4DfSvI1YCtTp6iuBE5MsryNWQk81JZ3A6cCtO0nAPsG69Ps82NVtamqVlfV6omJiaP/aSRJwAiDo6ouraqVVTXJ1MXtm6vq94FbgNe0YeuB69vyDW2dtv3mqqpWX9fuujoNWAXcPqq+JUmzWz73kKPu7cDWJO8Gvghc1epXAdck2cXUkcY6gKq6O8k24B7gAHBxVT0+/21LkmCegqOqbgVubcsPMM1dUVX1GHDhDPtfBlw2ug4lScPym+OSpC4GhySpi8EhSepicEiSuhgckqQuBockqYvBIUnqYnBIkroYHJKkLgaHJKmLwSFJ6mJwSJK6GBySpC4GhySpi8EhSepicEiSuhgckqQuBockqYvBIUnqYnBIkroYHJKkLgaHJKmLwSFJ6mJwSJK6GBySpC4GhySpi8EhSepicEiSuhgckqQuBockqYvBIUnqYnBIkroYHJKkLgaHJKmLwSFJ6mJwSJK6GBySpC4jC44kT0pye5L/SnJ3kr9q9dOS3Jbk/iQfTXJcqx/f1ne17ZMD73Vpq9+X5PxR9SxJmtsojzi+D5xTVS8EzgDWJDkbeA9wRVWtAvYDG9r4DcD+qnoOcEUbR5LTgXXA84E1wPuTLBth35KkWYwsOGrKd9vqse2ngHOA61p9C3BBW17b1mnbz02SVt9aVd+vqq8Cu4CzRtW3JGl2I73GkWRZkjuBPcB24CvAt6rqQBuyG1jRllcADwK07Y8CTx+sT7PP4O/amGRHkh179+4dxceRJDHi4Kiqx6vqDGAlU0cJz5tuWHvNDNtmqh/6uzZV1eqqWj0xMXG4LUuS5jAvd1VV1beAW4GzgROTLG+bVgIPteXdwKkAbfsJwL7B+jT7SJLm2SjvqppIcmJbfjLw68C9wC3Aa9qw9cD1bfmGtk7bfnNVVauva3ddnQasAm4fVd+SpNktn3vIYTsF2NLugDoG2FZVn0xyD7A1ybuBLwJXtfFXAdck2cXUkcY6gKq6O8k24B7gAHBxVT0+wr4lSbMYWXBU1V3Ai6apP8A0d0VV1WPAhTO812XAZUe7R0lSP785LknqYnBIkroYHJKkLgaHJKmLwSFJ6mJwSJK6GBySpC4GhySpi8EhSepicEiSugwVHEleNkxNkvTEN+wRx/uGrEmSnuBmneQwyS8DLwUmkrx1YNPPAz73W5KWoLlmxz0OeEob99SB+rf5yTM1JElLyKzBUVWfAT6T5Oqq+vo89SRJWsCGfR7H8Uk2AZOD+1TVOaNoSpK0cA0bHP8EfBD4EODT9yRpCRs2OA5U1QdG2okkaVEY9nbcTyT5oySnJHnawZ+RdiZJWpCGPeJY317fNlAr4NlHtx1J0kI3VHBU1WmjbkSStDgMFRxJLpquXlUfPrrtSJIWumFPVb14YPlJwLnAFwCDQ5KWmGFPVf3J4HqSE4BrRtKRJGlBO9xp1b8HrDqajUiSFodhr3F8gqm7qGBqcsPnAdtG1ZQkaeEa9hrHXw8sHwC+XlW7R9CPJGmBG+pUVZvs8L+ZmiH3JOAHo2xKkrRwDfsEwNcCtwMXAq8FbkvitOqStAQNe6rqL4AXV9UegCQTwL8D142qMUnSwjTsXVXHHAyN5n879pUkPYEMe8Txr0luAq5t678L3DialiRJC9lczxx/DvDMqnpbkt8BfgUI8DngI/PQnyRpgZnrdNOVwHcAqurjVfXWqnoLU0cbV466OUnSwjNXcExW1V2HFqtqB1OPkZUkLTFzBceTZtn25KPZiCRpcZgrOO5I8sZDi0k2ADtH05IkaSGbKzjeDLwhya1J/qb9fAb4Q+BNs+2Y5NQktyS5N8ndSd7U6k9Lsj3J/e31pFZPkvcm2ZXkriRnDrzX+jb+/iTrZ/qdkqTRm/Wuqqp6BHhpklcAL2jlT1XVzUO89wHgT6vqC0meCuxMsh34A+DTVXV5kkuAS4C3A69kasbdVcBLgA8AL2nPNn8HsJqpiRZ3JrmhqvZ3flZJ0lEw7PM4bgFu6XnjqnoYeLgtfyfJvcAKYC3w8jZsC3ArU8GxFvhwVRXw+SQnJjmljd1eVfsAWvis4SffKZEkzaN5+fZ3kkngRcBtTH0v5GCgPAw8ow1bATw4sNvuVpupfujv2JhkR5Ide/fuPdofQZLUjDw4kjwF+Bjw5qr69mxDp6nVLPWfLlRtqqrVVbV6YmLi8JqVJM1ppMGR5FimQuMjVfXxVn6knYKivR6cA2s3cOrA7iuBh2apS5LGYGTBkSTAVcC9VfW3A5tuAA7eGbUeuH6gflG7u+ps4NF2Kusm4LwkJ7U7sM5rNUnSGAw7yeHheBnweuBLSe5stT8HLge2te+CfIOpZ3zA1DQmrwJ2MfVM8zcAVNW+JO8C7mjj3nnwQrkkaf6NLDiq6j+Z/voEwLnTjC/g4hneazOw+eh1J0k6XD5TQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUheDQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUheDQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUpeRBUeSzUn2JPnyQO1pSbYnub+9ntTqSfLeJLuS3JXkzIF91rfx9ydZP6p+JUnDGeURx9XAmkNqlwCfrqpVwKfbOsArgVXtZyPwAZgKGuAdwEuAs4B3HAwbSdJ4jCw4quqzwL5DymuBLW15C3DBQP3DNeXzwIlJTgHOB7ZX1b6q2g9s52fDSJI0j+b7Gsczq+phgPb6jFZfATw4MG53q81UlySNyUK5OJ5pajVL/WffINmYZEeSHXv37j2qzUmSfmK+g+ORdgqK9rqn1XcDpw6MWwk8NEv9Z1TVpqpaXVWrJyYmjnrjkqQp8x0cNwAH74xaD1w/UL+o3V11NvBoO5V1E3BekpPaRfHzWk2SNCbLR/XGSa4FXg6cnGQ3U3dHXQ5sS7IB+AZwYRt+I/AqYBfwPeANAFW1L8m7gDvauHdW1aEX3CVJ82hkwVFVr5th07nTjC3g4hneZzOw+Si2Jkk6Agvl4rgkaZEwOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUheDQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUheDQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUheDQ5LUxeCQJHVZNMGRZE2S+5LsSnLJuPuRpKVqUQRHkmXA3wOvBE4HXpfk9PF2JUlL06IIDuAsYFdVPVBVPwC2AmvH3JMkLUmLJThWAA8OrO9uNUnSPFs+7gaGlGlq9VMDko3Axrb63ST3jbyrpeFk4JvjbmKhyHvG3YGm4d/ogCP8G33WMIMWS3DsBk4dWF8JPDQ4oKo2AZvms6mlIMmOqlo97j6kmfg3Ov8Wy6mqO4BVSU5LchywDrhhzD1J0pK0KI44qupAkj8GbgKWAZur6u4xtyVJS9KiCA6AqroRuHHcfSxBnv7TQuff6DxLVc09SpKkZrFc45AkLRAGh2bkNC9ayJJsTrInyZfH3ctSY3BoWk7zokXgamDNuJtYigwOzcRpXrSgVdVngX3j7mMpMjg0E6d5kTQtg0MzmXOaF0lLk8Ghmcw5zYukpcng0Eyc5kXStAwOTauqDgAHp3m5F9jmNC9aSJJcC3wO+MUku5NsGHdPS4XfHJckdfGIQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkI5Qkl9IsjXJV5Lck+TGJM911lY9US2aJwBKC1GSAP8MbKmqda12BvDMsTYmjZBHHNKReQXww6r64MFCVd3JwASRSSaT/EeSL7Sfl7b6KUk+m+TOJF9O8qtJliW5uq1/Kclb5v8jSbPziEM6Mi8Ads4xZg/wG1X1WJJVwLXAauD3gJuq6rL2/JOfA84AVlTVCwCSnDi61qXDY3BIo3cs8HftFNbjwHNb/Q5gc5JjgX+pqjuTPAA8O8n7gE8B/zaWjqVZeKpKOjJ3A780x5i3AI8AL2TqSOM4+PGDiH4N+B/gmiQXVdX+Nu5W4GLgQ6NpWzp8Bod0ZG4Gjk/yxoOFJC8GnjUw5gTg4ar6EfB6YFkb9yxgT1X9A3AVcGaSk4FjqupjwF8CZ87Px5CG56kq6QhUVSX5beDKJJcAjwFfA948MOz9wMeSXAjcAvxfq78ceFuSHwLfBS5i6imL/5jk4D91l478Q0idnB1XktTFU1WSpC4GhySpi8EhSepicEiSuhgckqQuBockqYvBIUnqYnBIkrr8P4LIlTik/npxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25041ae2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive cases: 11.524% of all\n"
     ]
    }
   ],
   "source": [
    "# There's nothing to do here, just execute the cell and view the plot and print results.\n",
    "# Cells like these are here only for your convenience and to help you understand the task better\n",
    "plt.bar([0, 1], [len(bank_output[bank_output == 0]), len(bank_output[bank_output == 1])])\n",
    "plt.xticks([0, 1])\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Positive cases: {:.3f}% of all\".format((bank_output['y'].sum() / len(bank_output['y']) * 100)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. More features  \n",
    "The score is pretty high. But can we improve it? One way to try and improve it is to use polynomial features. As we saw, this creates all possible multiples of input features. In the real world, this corresponds to **feature interaction**.\n",
    "\n",
    "We create a model for quadratic features (`degree = 2`). Then save it in the variable `quad_feature_transformer`. Also, we set `interaction_only` to True: let's suppose we don't want to square each feature. This means that we have all single features $x_1, x_2, \\dots$ and all interactions $x_1x_2, x_1x_3, \\dots$ but no $x_1^2, x_2^2, \\dots$\n",
    "\n",
    "Using it, transform all `bank_features`. Save them in the variable `bank_features_quad`.\n",
    "\n",
    "Note how the number of features exploded: from 51 we get more than 1300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PolynomialFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1d9e945981589431cb60fb23f3e292a4",
     "grade": false,
     "grade_id": "cell-f4b5c98c2c3d7ef3",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "quad_feature_transformer = PolynomialFeatures(2, interaction_only=True)\n",
    "quad_feature_transformer.fit(bank_features)\n",
    "bank_features_quad = quad_feature_transformer.transform(bank_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7dc305e61d9755d1fbd8fcab1157e6cd",
     "grade": true,
     "grade_id": "cell-b42599d51988eda2",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(quad_feature_transformer.degree, 2)\n",
    "assert_equal(quad_feature_transformer.interaction_only, True)\n",
    "assert_equal(bank_features_quad.shape, (4521, 1327))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Train a model on the quadratic features \n",
    "You know the drill. Fit a logistic regression model with all data in `bank_features_quad` and `bank_output`. Use `C = 1e6`. Save it in `bank_model_quad`. Score it and save the score in the variable `accuracy_score_quad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "352a0967d85055d7231829c734ee88af",
     "grade": false,
     "grade_id": "cell-13ea36255860f15b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.899\n"
     ]
    }
   ],
   "source": [
    "bank_model_quad = LogisticRegression(C=1e6).fit(bank_features_quad, bank_output['y'])\n",
    "accuracy_score_quad = bank_model_quad.score(bank_features_quad, bank_output['y'])\n",
    "\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy_score_quad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7913ad0cba092aec2bcaa500fc677e96",
     "grade": true,
     "grade_id": "cell-4718eb80c10d4a16",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_not_none(bank_model_quad)\n",
    "assert_equal(bank_model_quad.C, 1e6)\n",
    "assert_equal(len(bank_model_quad.coef_[0]), bank_features_quad.shape[1]) # This is a simple check that the model has been trained\n",
    "assert_almost_equal(accuracy_score_quad, 0.8986949789869498, delta = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting... we have many more features but the accuracy actually dropped a little. We would observe the same behaviour if we took polynomials of degree 3: more than 20 000 features and accuracy less than 0.87.\n",
    "\n",
    "This is our first example of model selection. Why is the seemingly more complex model less accurate? There are two main reasons:\n",
    "* As we said, the default score (accuracy) is not good for this dataset, so its values aren't too relevant.\n",
    "* The number of features is alarmingly high. This leads to what we call \"overfitting\": our model is too complex. We can't quite catch it with this scoring scheme but we will be able to do that later.\n",
    "\n",
    "We can try a lot of things: test our model better, improve our scoring schemes, come up with better features, etc. In general, we need to take care of several things:\n",
    "* Are all parameters relevant? Can we discard some of them and how?\n",
    "* How do we deal with imbalanced data?\n",
    "* Is logistic regression the best type of model overall? Are there models that do better on this data?\n",
    "* What are the best hyperparameters for the model? We chose `C = 1e6` arbitrarily.\n",
    "\n",
    "We'll continue to do this next time. Let's try just one more thing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Perform normalization and compare results \n",
    "We saw very strange results. A part of the problem might be that our data isn't normalized.\n",
    "\n",
    "Use the `MinMaxScaler` to scale all values in `bank_features_quad`. Save them in `bank_features_quad_scaled`. This will take several seconds.\n",
    "\n",
    "Perform a logistic regression on the new, scaled features: `bank_features_quad_scaled` and `bank_output`. Use the same parameters to score it.\n",
    "\n",
    "You should observe that the score improved the score significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "703dd691c73f0b5a7202380746383250",
     "grade": false,
     "grade_id": "cell-972ff9771d00156b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "bank_features_quad_scaled = min_max_scaler.fit_transform(bank_features_quad)\n",
    "bank_model_quad_scaled = LogisticRegression(C=1e6).fit(bank_features_quad_scaled, bank_output['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score_quad_scaled = bank_model_quad_scaled.score(bank_features_quad_scaled, bank_output['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.969033399690334"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score_quad_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "01d5030b116296f7babfc308517b8f15",
     "grade": true,
     "grade_id": "cell-617300ee8ad8e106",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_not_none(bank_model_quad)\n",
    "assert_equal(bank_model_quad.C, 1e6)\n",
    "assert_equal(len(bank_model_quad.coef_[0]), bank_features_quad.shape[1])\n",
    "assert_almost_equal(accuracy_score_quad_scaled, 0.969033399690334, delta = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, if you do the test, scaling the original features (instead of the quadratic ones) doesn't improve the score much. This is partly because it isn't the best score. Also, our results are a great reminder that **if we have many uncorrelated features, it's almost always a good idea to rescale them**. You can read some papers online, or use the forums to ask if you're interested why exactly this happens.\n",
    "\n",
    "The main takeaway from this lab is: working with `scikit-learn` is easy but in order to get meaningful results, you need to understand what you're doing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
